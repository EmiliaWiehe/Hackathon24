{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/johann/anaconda3/envs/pytorch/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "class ImageClassificationDataset(Dataset):\n",
    "    def __init__(self, positive_dir, negative_dir, transform=None):\n",
    "        self.positive_dir = positive_dir\n",
    "        self.negative_dir = negative_dir\n",
    "        self.transform = transform\n",
    "        self.positive_files = [(os.path.join(positive_dir, f), 1) for f in os.listdir(positive_dir) if f.endswith('.png')]\n",
    "        self.negative_files = [(os.path.join(negative_dir, f), 0) for f in os.listdir(negative_dir) if f.endswith('.png')]\n",
    "        self.all_files = self.positive_files + self.negative_files\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.all_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file_path, label = self.all_files[idx]\n",
    "        image = Image.open(file_path).convert(\"RGB\")\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image, label, os.path.basename(file_path)\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "positive_dir = \"data/train_images/Train/Positive\"\n",
    "negative_dir = \"data/train_images/Train/Negative\"\n",
    "dataset = ImageClassificationDataset(positive_dir, negative_dir, transform)\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "        self.fc1 = nn.Linear(64 * 32 * 32, 128)\n",
    "        self.fc2 = nn.Linear(128, 2)  # Output: 2 classes (positive and negative)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 64 * 32 * 32)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "model = SimpleCNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 0.3466\n",
      "Epoch [2/10], Loss: 0.2129\n",
      "Epoch [3/10], Loss: 0.1981\n",
      "Epoch [4/10], Loss: 0.1661\n",
      "Epoch [5/10], Loss: 0.1510\n",
      "Epoch [6/10], Loss: 0.1764\n",
      "Epoch [7/10], Loss: 0.1322\n",
      "Epoch [8/10], Loss: 0.1040\n",
      "Epoch [9/10], Loss: 0.0789\n",
      "Epoch [10/10], Loss: 0.0565\n",
      "Training complete.\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for images, labels, _ in dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(dataloader):.4f}\")\n",
    "\n",
    "print(\"Training complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: mask_20241202-163759-647.png, Prediction: 1, Label: 1\n",
      "File: mask_20241126-162109-143.png, Prediction: 1, Label: 1\n",
      "File: mask_20241203-170422-829.png, Prediction: 1, Label: 1\n",
      "File: mask_20241203-083122-181.png, Prediction: 1, Label: 1\n",
      "Opening in existing browser session.\n",
      "File: mask_20241204-092652-029.png, Prediction: 1, Label: 1\n",
      "Opening in existing browser session.\n",
      "File: mask_20241203-084721-591.png, Prediction: 1, Label: 1\n",
      "Opening in existing browser session.\n",
      "File: mask_20241203-164446-728.png, Prediction: 1, Label: 1\n",
      "Opening in existing browser session.\n",
      "File: mask_20241203-163802-444.png, Prediction: 1, Label: 1\n",
      "Opening in existing browser session.\n",
      "File: mask_20241203-084300-162.png, Prediction: 1, Label: 1\n",
      "Opening in existing browser session.\n",
      "File: mask_20241203-160929-199.png, Prediction: 1, Label: 1\n",
      "Opening in existing browser session.\n",
      "File: mask_20241203-161443-013.png, Prediction: 1, Label: 1\n",
      "Opening in existing browser session.\n",
      "File: mask_20241203-171123-730.png, Prediction: 1, Label: 1\n",
      "Opening in existing browser session.\n",
      "File: mask_20241203-171331-896.png, Prediction: 1, Label: 1\n",
      "Opening in existing browser session.\n",
      "File: mask_20241203-084242-404.png, Prediction: 0, Label: 1\n",
      "Opening in existing browser session.\n",
      "File: mask_20241202-164247-925.png, Prediction: 1, Label: 1\n",
      "Opening in existing browser session.\n",
      "File: mask_20241203-083132-158.png, Prediction: 1, Label: 1\n",
      "Opening in existing browser session.\n",
      "File: mask_20241126-160449-438.png, Prediction: 1, Label: 1\n",
      "Opening in existing browser session.\n",
      "File: mask_20241202-145831-221.png, Prediction: 1, Label: 1\n",
      "Opening in existing browser session.\n",
      "File: mask_20241203-083124-531.png, Prediction: 0, Label: 1\n",
      "Opening in existing browser session.\n",
      "File: mask_20241203-170228-911.png, Prediction: 1, Label: 1\n",
      "Opening in existing browser session.\n",
      "File: mask_20241202-114443-932.png, Prediction: 1, Label: 1\n",
      "Opening in existing browser session.\n",
      "File: mask_20241203-083142-709.png, Prediction: 1, Label: 1\n",
      "Opening in existing browser session.\n",
      "File: mask_20241126-144903-306.png, Prediction: 1, Label: 1\n",
      "Opening in existing browser session.\n",
      "File: mask_20241204-092352-170.png, Prediction: 1, Label: 1\n",
      "Opening in existing browser session.\n",
      "File: mask_20241203-171533-102.png, Prediction: 1, Label: 1\n",
      "Opening in existing browser session.\n",
      "File: mask_20241203-171523-033.png, Prediction: 1, Label: 1\n",
      "Opening in existing browser session.\n",
      "File: mask_20241203-165642-109.png, Prediction: 1, Label: 1\n",
      "Opening in existing browser session.\n",
      "File: mask_20241203-082801-112.png, Prediction: 0, Label: 1\n",
      "Opening in existing browser session.\n",
      "File: mask_20241203-084256-163.png, Prediction: 1, Label: 1\n",
      "Opening in existing browser session.\n",
      "File: mask_20241126-144709-812.png, Prediction: 0, Label: 1\n",
      "Opening in existing browser session.\n",
      "File: mask_20241203-164353-661.png, Prediction: 1, Label: 1\n",
      "Opening in existing browser session.\n",
      "File: mask_20241203-165226-429.png, Prediction: 1, Label: 1\n",
      "Opening in existing browser session.\n",
      "File: mask_20241203-171116-168.png, Prediction: 1, Label: 1\n",
      "Opening in existing browser session.\n",
      "File: mask_20241202-170238-563.png, Prediction: 1, Label: 1\n",
      "Opening in existing browser session.\n",
      "File: mask_20241126-144446-573.png, Prediction: 1, Label: 1\n",
      "Opening in existing browser session.\n",
      "File: mask_20241203-083758-975.png, Prediction: 1, Label: 1\n",
      "Opening in existing browser session.\n",
      "File: mask_20241203-171527-321.png, Prediction: 0, Label: 0\n",
      "Opening in existing browser session.\n",
      "Opening in existing browser session.\n",
      "Opening in existing browser session.\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/train_images/Train/Positive/mask_20241203-171527-321.png'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [7], line 29\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFile: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilename\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Prediction: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprediction\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Label: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlabel\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# print the original image\u001b[39;00m\n\u001b[0;32m---> 29\u001b[0m image \u001b[38;5;241m=\u001b[39m \u001b[43mImage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpositive_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     30\u001b[0m image\u001b[38;5;241m.\u001b[39mshow()\n\u001b[1;32m     31\u001b[0m idx \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.9/site-packages/PIL/Image.py:3092\u001b[0m, in \u001b[0;36mopen\u001b[0;34m(fp, mode, formats)\u001b[0m\n\u001b[1;32m   3089\u001b[0m     filename \u001b[38;5;241m=\u001b[39m fp\n\u001b[1;32m   3091\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m filename:\n\u001b[0;32m-> 3092\u001b[0m     fp \u001b[38;5;241m=\u001b[39m \u001b[43mbuiltins\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3093\u001b[0m     exclusive_fp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   3095\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/train_images/Train/Positive/mask_20241203-171527-321.png'"
     ]
    }
   ],
   "source": [
    "# Function to evaluate the model and output file names\n",
    "def evaluate_model(model, dataloader):\n",
    "    model.eval()\n",
    "    all_predictions = []\n",
    "    all_labels = []\n",
    "    all_filenames = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels, filenames in dataloader:\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            all_predictions.extend(predicted.numpy())\n",
    "            all_labels.extend(labels.numpy())\n",
    "            all_filenames.extend(filenames)\n",
    "\n",
    "    return all_predictions, all_labels, all_filenames\n",
    "\n",
    "# Evaluate the model\n",
    "test_dataset = ImageClassificationDataset(positive_dir, negative_dir, transform)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "predictions, labels, filenames = evaluate_model(model, test_dataloader)\n",
    "\n",
    "# Print the results\n",
    "idx = 0\n",
    "for filename, prediction, label in zip(filenames, predictions, labels):\n",
    "    print(f\"File: {filename}, Prediction: {prediction}, Label: {label}\")\n",
    "    # print the original image\n",
    "    image = Image.open(os.path.join(positive_dir, filename))\n",
    "    image.show()\n",
    "    idx += 1\n",
    "    if idx == 5:\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
