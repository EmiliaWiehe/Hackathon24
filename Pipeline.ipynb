{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "def preprocess_image(image_path):\n",
    "    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    return image\n",
    "\n",
    "part_image = preprocess_image(\"data/dummy/part_1/part_1.png\")\n",
    "gripper_image = preprocess_image(\"data/dummy/part_1/gripper_2.png\")\n",
    "\n",
    "# gripper_image change black to white\n",
    "# gripper_image[gripper_image == 0] = 255\n",
    "# gripper_image[gripper_image == 255]\n",
    "\n",
    "# convert to PIL image\n",
    "# part_image = Image.fromarray(part_image)\n",
    "# gripper_image = Image.fromarray(gripper_image)\n",
    "\n",
    "# part_image.show()\n",
    "# gripper_image.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_edge_mask(image):\n",
    "    edges = cv2.Canny(image, 100, 200)\n",
    "    return edges\n",
    "\n",
    "part_edges = generate_edge_mask(part_image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_valid_position(part_edges, gripper_image, x, y):\n",
    "    part_height, part_width = part_edges.shape\n",
    "    gripper_height, gripper_width = gripper_image.shape\n",
    "    \n",
    "    if x + gripper_width > part_width or y + gripper_height > part_height:\n",
    "        return False\n",
    "    \n",
    "    for i in range(gripper_height):\n",
    "        for j in range(gripper_width):\n",
    "            if gripper_image[i, j] > 0 and part_edges[y + i, x + j] > 0:\n",
    "                return False\n",
    "    return True\n",
    "\n",
    "def find_valid_position(part_edges, gripper_image):\n",
    "    part_height, part_width = part_edges.shape\n",
    "    gripper_height, gripper_width = gripper_image.shape\n",
    "    \n",
    "    for y in range(part_height - gripper_height):\n",
    "        for x in range(part_width - gripper_width):\n",
    "            if is_valid_position(part_edges, gripper_image, x, y):\n",
    "                return x, y\n",
    "    return None\n",
    "\n",
    "position = find_valid_position(part_edges, gripper_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(51, 9)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def place_gripper(part_image, gripper_image, position):\n",
    "    x, y = position\n",
    "    part_image_with_gripper = part_image.copy()\n",
    "    part_image_with_gripper[y:y+gripper_image.shape[0], x:x+gripper_image.shape[1]] = gripper_image\n",
    "    return part_image_with_gripper\n",
    "\n",
    "if position:\n",
    "    result_image = place_gripper(part_image, gripper_image, position)\n",
    "    cv2.imwrite(\"data/Output_Images/test.png\", result_image)\n",
    "else:\n",
    "    print(\"No valid position found for the gripper.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
